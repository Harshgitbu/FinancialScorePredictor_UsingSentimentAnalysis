{
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "outputs": [],
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import emoji"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "outputs": [],
      "metadata": {},
      "source": [
        "file_path = \"financial_tweets_21_to_24.csv\"  # Adjust if needed\n",
        "df = pd.read_csv(file_path, encoding=\"utf-8\")\n",
        "print(\"Original shape:\", df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "outputs": [],
      "metadata": {},
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "outputs": [],
      "metadata": {},
      "source": [
        "columns_to_drop = ['image_url','proxy_image_url','image_dimensions','thumbnail_url','proxy_thumbnail_url','thumbnail_dimensions','url','tweet_type']\n",
        "df = df.drop(columns=columns_to_drop,axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "outputs": [],
      "metadata": {},
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "outputs": [],
      "metadata": {},
      "source": [
        "# Step 1: Drop rows with missing timestamps or descriptions\n",
        "df = df.dropna(subset=[\"timestamp\", \"description\"])\n",
        "# Step 2: Convert timestamp to datetime\n",
        "df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], errors=\"coerce\")\n",
        "df = df.dropna(subset=[\"timestamp\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "outputs": [],
      "metadata": {},
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "outputs": [],
      "metadata": {},
      "source": [
        "# Step 3: Clean description\n",
        "def clean_text(text):\n",
        "    text = str(text).lower()\n",
        "    text = re.sub(r\"http\\S+\", \"\", text)              # remove URLs\n",
        "    text = emoji.replace_emoji(text, replace='')     # remove emojis\n",
        "    text = re.sub(r\"[^\\w\\s]\", \"\", text)              # remove punctuation\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()         # remove extra spaces\n",
        "    return text\n",
        "\n",
        "df[\"clean_text\"] = df[\"description\"].apply(clean_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "outputs": [],
      "metadata": {},
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "outputs": [],
      "metadata": {},
      "source": [
        "# Step 4: Remove duplicates and empty clean_text\n",
        "df = df[df[\"clean_text\"].str.strip() != \"\"]\n",
        "df = df.drop_duplicates(subset=[\"clean_text\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "outputs": [],
      "metadata": {},
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "outputs": [],
      "metadata": {},
      "source": [
        "df['financial_info'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "outputs": [],
      "metadata": {},
      "source": [
        "df['financial_info'][10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "outputs": [],
      "metadata": {},
      "source": [
        "df['financial_info'][314731]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "outputs": [],
      "metadata": {},
      "source": [
        "import ast\n",
        "def parse_financial_info(val):\n",
        "    try:\n",
        "        parsed = ast.literal_eval(val)\n",
        "        if isinstance(parsed, list):\n",
        "            return parsed\n",
        "        return []\n",
        "    except:\n",
        "        return []\n",
        "\n",
        "df[\"parsed_financial_info\"] = df[\"financial_info\"].apply(parse_financial_info)\n",
        "\n",
        "# Step 3: Extract unique keys and build rows\n",
        "def flatten_row(dict_list):\n",
        "    flattened = {}\n",
        "    if not dict_list:\n",
        "        return flattened\n",
        "    for d in dict_list:\n",
        "        if isinstance(d, dict):\n",
        "            for key, value in d.items():\n",
        "                if value is None or value == \"\":\n",
        "                    continue\n",
        "                if key in flattened:\n",
        "                    flattened[key] += f\", {value}\"\n",
        "                else:\n",
        "                    flattened[key] = str(value)\n",
        "    return flattened\n",
        "\n",
        "# Step 4: Apply the flattening function and expand to columns\n",
        "expanded_df = df[\"parsed_financial_info\"].apply(flatten_row).apply(pd.Series)\n",
        "\n",
        "# Step 5: Merge with original DataFrame\n",
        "df_cleaned = pd.concat([df.drop(columns=[\"parsed_financial_info\"]), expanded_df], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "outputs": [],
      "metadata": {},
      "source": [
        "df_cleaned"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "outputs": [],
      "metadata": {},
      "source": [
        "df_cleaned.drop(columns='financial_info',axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "outputs": [],
      "metadata": {},
      "source": [
        "df_cleaned.reset_index(drop=True).to_csv('twitter_data_cleaned.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "description": null,
    "save_output": true,
    "language_info": {
      "name": "python"
    }
  }
}